# LiftLogic Environment Configuration
# Copy this to .env and configure as needed

# ===================
# LLM PROVIDER (No API keys needed!)
# ===================

# Provider: "oauth" (Gemini via ADC) or "ollama" (local)
# Default: oauth (zero cost via Google AI quota)
LLM_PROVIDER=oauth

# For OAuth/ADC, run once: gcloud auth application-default login
# No API key required!

# ===================
# OPTIONAL - Paths
# ===================

# Data directory for databases and indexes
DATA_DIR=data

# SQLite database path
DB_PATH=data/liftlogic.db

# FAISS index directory
FAISS_INDEX_PATH=data/indices/faiss

# ===================
# OPTIONAL - Gemini (via OAuth/ADC)
# ===================

# Model to use (gemini-2.0-flash, gemini-1.5-pro, etc.)
GEMINI_MODEL=gemini-2.0-flash

# Temperature for generation (0.0-1.0)
GEMINI_TEMPERATURE=0.1

# Rate limit (requests per minute)
GEMINI_RATE_LIMIT_RPM=60

# ===================
# OPTIONAL - Neo4j
# ===================
# Leave empty to use in-memory NetworkX graph only

NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=
NEO4J_DATABASE=neo4j

# ===================
# OPTIONAL - Ollama (Local LLM)
# ===================
# Alternative to Gemini for fully offline usage

OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ===================
# OPTIONAL - Search
# ===================

# Sentence transformer model for embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Embedding dimension (must match model)
EMBEDDING_DIMENSION=384

# Default search result limit
SEARCH_DEFAULT_LIMIT=20

# ===================
# OPTIONAL - API
# ===================

API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false

# ===================
# OPTIONAL - Monitoring
# ===================

PHOENIX_ENABLED=false
PHOENIX_ENDPOINT=http://localhost:6006
